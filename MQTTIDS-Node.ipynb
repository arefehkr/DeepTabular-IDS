{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0,1\n",
      "Shape: label\n",
      "Normal                             68890\n",
      "encoded-payload-flood-Attack       40000\n",
      "Connect-Disconnect-Flood-Attack    40000\n",
      "publish-subscribe-flood-Attack     40000\n",
      "Ping-Req-Flood-Attack              40000\n",
      "slow-publish-Attack                40000\n",
      "unvalid-publish-flood-Attack       40000\n",
      "very-large-message-flood-Attack    40000\n",
      "valid-publish-flood-Attack         40000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=0,1\n",
    "import os, sys\n",
    "import time\n",
    "sys.path.insert(0, '..')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import lib\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from qhoptim.pyt import QHAdam\n",
    "\n",
    "# read the data\n",
    "data = pd.read_pickle('C:/Users/bcccu/Desktop/MQTTIDS/pkl/MQTTIDS_balanced.pkl')\n",
    "# df = pd.read_csv('concatenated_data.csv')\n",
    "print(f\"Shape:\",data['label'].value_counts())\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ make sure you're using torch version `>= 1.1.0`, the code will silently fail even on 1.0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Shape after removing duplicates: label\n",
      "Normal                             68882\n",
      "encoded-payload-flood-Attack       40000\n",
      "Connect-Disconnect-Flood-Attack    40000\n",
      "publish-subscribe-flood-Attack     40000\n",
      "Ping-Req-Flood-Attack              40000\n",
      "slow-publish-Attack                40000\n",
      "unvalid-publish-flood-Attack       40000\n",
      "very-large-message-flood-Attack    40000\n",
      "valid-publish-flood-Attack         40000\n",
      "Name: count, dtype: int64\n",
      "Categorical features: ['flowid', 'TCPid', 'srcIP', 'dstIP', 'clientID', 'topic', 'startTime', 'endTime', 'username', 'password', 'fwdTobwdPacketRatio', 'bwdTofwdPacketRatio', 'willmsgLen', 'willtopicLen', 'protocolName', 'label', 'source_file']\n",
      "Columns dropped successfully! Shape: (388882, 387)\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "print(\" Shape after removing duplicates:\", df['label'].value_counts())\n",
    "categorical_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "# Drop only the columns that exist in the dataframe\n",
    "columns_to_drop = ['flowid', 'TCPid', 'srcIP', 'dstIP', 'srcPort', 'dstPort', 'clientID', 'clientIDlen', 'topic', 'startTime', 'endTime', 'username', 'password', 'fwdTobwdPacketRatio', 'bwdTofwdPacketRatio', 'willmsgLen', 'willtopicLen', 'protocolName', 'source_file']\n",
    "df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])\n",
    "print(\"Columns dropped successfully! Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df Cleaning Done! Shape after removing duplicates: (388882, 386)\n",
      "Label distribution:\n",
      " label\n",
      "Normal                             68882\n",
      "encoded-payload-flood-Attack       40000\n",
      "Connect-Disconnect-Flood-Attack    40000\n",
      "publish-subscribe-flood-Attack     40000\n",
      "Ping-Req-Flood-Attack              40000\n",
      "slow-publish-Attack                40000\n",
      "unvalid-publish-flood-Attack       40000\n",
      "very-large-message-flood-Attack    40000\n",
      "valid-publish-flood-Attack         40000\n",
      "Name: count, dtype: int64\n",
      "Missing testues handled successfully!\n",
      "Shape after handling missing values: (388882, 386)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "# Print dfset summary\n",
    "print(\"df Cleaning Done! Shape after removing duplicates:\", X.shape)\n",
    "print(\"Label distribution:\\n\", y.value_counts())\n",
    "\n",
    "# Fill missing testues\n",
    "for col in X.columns:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        if X[col].dtype == 'object':  # Categorical\n",
    "            X[col] = X[col].fillna(X[col].mode()[0])  # Assign explicitly\n",
    "            print(\"Column:\", col, \"is categorical\")\n",
    "        else:  # Numerical\n",
    "            X[col] = X[col].fillna(X[col].median())  # Assign explicitly\n",
    "\n",
    "print(\"Missing testues handled successfully!\")\n",
    "print(\"Shape after handling missing values:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaning Done! Shape after removing duplicates: (388882, 386)\n",
      "Label distribution:\n",
      " label\n",
      "Normal                             68882\n",
      "encoded-payload-flood-Attack       40000\n",
      "Connect-Disconnect-Flood-Attack    40000\n",
      "publish-subscribe-flood-Attack     40000\n",
      "Ping-Req-Flood-Attack              40000\n",
      "slow-publish-Attack                40000\n",
      "unvalid-publish-flood-Attack       40000\n",
      "very-large-message-flood-Attack    40000\n",
      "valid-publish-flood-Attack         40000\n",
      "Name: count, dtype: int64\n",
      "Missing testues handled successfully!\n",
      "Shape after handling missing values: (388882, 386)\n"
     ]
    }
   ],
   "source": [
    "data = df.copy()\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['label'])\n",
    "y = data['label']\n",
    "\n",
    "# Print dataset summary\n",
    "print(\"Data Cleaning Done! Shape after removing duplicates:\", X.shape)\n",
    "print(\"Label distribution:\\n\", y.value_counts())\n",
    "\n",
    "# Fill missing testues\n",
    "for col in X.columns:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        if X[col].dtype == 'object':  # Categorical\n",
    "            X[col] = X[col].fillna(X[col].mode()[0])  # Assign explicitly\n",
    "            print(\"Column:\", col, \"is categorical\")\n",
    "        else:  # Numerical\n",
    "            X[col] = X[col].fillna(X[col].median())  # Assign explicitly\n",
    "\n",
    "print(\"Missing testues handled successfully!\")\n",
    "print(\"Shape after handling missing values:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed!\n",
      "Train shape: (311105, 386), Test shape: (77777, 386)\n",
      "Class names: ['Connect-Disconnect-Flood-Attack' 'Normal' 'Ping-Req-Flood-Attack'\n",
      " 'encoded-payload-flood-Attack' 'publish-subscribe-flood-Attack'\n",
      " 'slow-publish-Attack' 'unvalid-publish-flood-Attack'\n",
      " 'valid-publish-flood-Attack' 'very-large-message-flood-Attack']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
      "C:\\Users\\bcccu\\AppData\\Local\\Temp\\ipykernel_35596\\1835829437.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['label'])  # Assuming 'label' is the target column\n",
    "y = data['label']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split data into 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "\n",
    "print(\"Data split completed!\")\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "\n",
    "# Ensure the LabelEncoder is fitted before accessing classes_\n",
    "if hasattr(label_encoder, 'classes_'):\n",
    "\tclass_names = label_encoder.classes_\n",
    "else:\n",
    "\tlabel_encoder.fit(y)  # Fit the LabelEncoder if not already fitted\n",
    "\tclass_names = label_encoder.classes_\n",
    "\n",
    "print(\"Class names:\", class_names)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Combine train and test sets for encoding\n",
    "combined = pd.concat([X_train, X_test], axis=0)\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoder = LabelEncoder()\n",
    "for col in combined.select_dtypes(include=['object']).columns:\n",
    "\tcombined[col] = label_encoder.fit_transform(combined[col].astype(str))\n",
    "\n",
    "# Split back into train and test sets\n",
    "X_train = combined.iloc[:X_train.shape[0], :]\n",
    "X_test = combined.iloc[X_train.shape[0]:, :]\n",
    "\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].isnull().sum() > 0:\n",
    "        if X_train[col].dtype == 'object':  # Categorical\n",
    "            X_train[col] = X_train[col].fillna(X_train[col].mode()[0])  # Assign explicitly\n",
    "            X_test[col] = X_test[col].fillna(X_test[col].mode()[0])  # Assign explicitly\n",
    "        else:  # Numerical\n",
    "            X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
    "            X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
    "\n",
    "\n",
    "\n",
    "# Convert to Float32 for PyTorch compatibility\n",
    "X_train, X_test = X_train.astype(np.float32), X_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lib.trainer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Remove this line: from lib.qhadam import QHAdam\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mqhoptim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QHAdam  \u001b[38;5;66;03m# Use this instead\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lib.trainer'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qhoptim.pyt import QHAdam  # This works\n",
    "# Restore the deprecated alias temporarily\n",
    "if not hasattr(np, 'int'):\n",
    "    np.int = int\n",
    "    np.float = float\n",
    "    np.bool = bool\n",
    "\n",
    "import lib  # Now import your library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lib\n",
    "from lib.trainer import Trainer\n",
    "# Remove this line: from lib.qhadam import QHAdam\n",
    "from qhoptim.pyt import QHAdam  # Use this instead\n",
    "\n",
    "# Set up optimizer parameters\n",
    "optimizer_params = {'nus': (0.7, 1.0), 'betas': (0.95, 0.998)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m      3\u001b[0m y_train \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(y_train)\n\u001b[1;32m----> 4\u001b[0m y_test_final \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(\u001b[43my_test_final\u001b[49m)\n\u001b[0;32m      5\u001b[0m y_temp \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(y_temp)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasses:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_train\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test_final' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test_final = le.transform(y_test_final)\n",
    "y_temp = le.transform(y_temp)\n",
    "print(\"Classes:\", y_train.shape)\n",
    "print(\"Classes:\", len(class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train))  # should now be 10\n",
    "print(\"Number of classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'lib' has no attribute 'DenseBlock'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 85\u001b[0m\n\u001b[0;32m     81\u001b[0m input_dim \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     82\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(data\u001b[38;5;241m.\u001b[39my_train))  \u001b[38;5;66;03m# should be 10\u001b[39;00m\n\u001b[0;32m     84\u001b[0m model \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m---> 85\u001b[0m     \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDenseBlock\u001b[49m(\n\u001b[0;32m     86\u001b[0m         input_dim\u001b[38;5;241m=\u001b[39minput_dim,\n\u001b[0;32m     87\u001b[0m         layer_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[0;32m     88\u001b[0m         num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     89\u001b[0m         tree_dim\u001b[38;5;241m=\u001b[39mnum_classes,  \u001b[38;5;66;03m# must match label count\u001b[39;00m\n\u001b[0;32m     90\u001b[0m         depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     91\u001b[0m         flatten_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     92\u001b[0m         choice_function\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mentmax15,\n\u001b[0;32m     93\u001b[0m         bin_function\u001b[38;5;241m=\u001b[39mlib\u001b[38;5;241m.\u001b[39mentmoid15\n\u001b[0;32m     94\u001b[0m     ),\n\u001b[0;32m     95\u001b[0m     lib\u001b[38;5;241m.\u001b[39mLambda(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# [B, C, D]  [B, C]\u001b[39;00m\n\u001b[0;32m     96\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m#  5. Initialize with dummy input (optional but recommended)\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'lib' has no attribute 'DenseBlock'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)  # one single fit\n",
    "class_names = le.classes_\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_temp, X_test_final, y_temp, y_test_final = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "X_train_final, X_valid, y_train_final, y_valid = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "X_train_final = X_train_final.astype(np.float32)\n",
    "X_valid = X_valid.astype(np.float32)\n",
    "X_test_final = X_test_final.astype(np.float32)\n",
    "\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].isnull().sum() > 0:\n",
    "        if X_train[col].dtype == 'object':  # Categorical\n",
    "            X_train[col] = X_train[col].fillna(X_train[col].mode()[0])  # Assign explicitly\n",
    "            X_test[col] = X_test[col].fillna(X_test[col].mode()[0])  # Assign explicitly\n",
    "            X_valid[col] = X_valid[col].fillna(X_valid[col].mode()[0])  # Assign explicitly\n",
    "        else:  # Numerical\n",
    "            X_train[col] = X_train[col].fillna(X_train[col].median())  # Assign explicitly\n",
    "            X_test[col] = X_test[col].fillna(X_test[col].median())  # Assign explicitly\n",
    "            X_valid[col] = X_valid[col].fillna(X_valid[col].median())  # Assign explicitly\n",
    "\n",
    "# Convert to Float32 for PyTorch compatibility\n",
    "X_train, X_test, X_valid = X_train.astype(np.float32), X_test.astype(np.float32), X_valid.astype(np.float32)\n",
    "# Replace NaN with column median\n",
    "X_train = X_train.fillna(X_train.median())\n",
    "X_valid = X_valid.fillna(X_valid.median())\n",
    "X_test = X_test.fillna(X_test.median())\n",
    "\n",
    "# Replace Infs with max finite value in each column\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan).fillna(X_train.median())\n",
    "X_valid = X_valid.replace([np.inf, -np.inf], np.nan).fillna(X_valid.median())\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan).fillna(X_test.median())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  3. Define dataset wrapper\n",
    "class CustomDataset:\n",
    "    def __init__(self, X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "        self.X_train = X_train.values if hasattr(X_train, 'values') else X_train\n",
    "        self.y_train = y_train if isinstance(y_train, np.ndarray) else y_train.values\n",
    "        self.X_valid = X_valid.values if hasattr(X_valid, 'values') else X_valid\n",
    "        self.y_valid = y_valid if isinstance(y_valid, np.ndarray) else y_valid.values\n",
    "        self.X_test = X_test.values if hasattr(X_test, 'values') else X_test\n",
    "        self.y_test = y_test if isinstance(y_test, np.ndarray) else y_test.values\n",
    "\n",
    "#  Replace NaNs and Infs in X_train_final, X_valid, X_test_final\n",
    "\n",
    "for df in [X_train_final, X_valid, X_test_final]:\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace inf with nan\n",
    "    df.fillna(df.median(), inplace=True)  # Fill nan with median\n",
    "\n",
    "X_train_final = X_train_final.astype(np.float32)\n",
    "X_valid = X_valid.astype(np.float32)\n",
    "X_test_final = X_test_final.astype(np.float32)\n",
    "       \n",
    "\n",
    "data = CustomDataset(X_train_final, y_train_final, X_valid, y_valid, X_test_final, y_test_final)\n",
    "\n",
    "#  4. Define model\n",
    "input_dim = data.X_train.shape[1]\n",
    "num_classes = len(np.unique(data.y_train))  # should be 10\n",
    "\n",
    "\n",
    "from rtdl import DenseBlock, Lambda, entmax15, entmoid15\n",
    "\n",
    "model = nn.Sequential(\n",
    "    DenseBlock(\n",
    "        input_dim=input_dim,\n",
    "        layer_dim=128,\n",
    "        num_layers=3,\n",
    "        tree_dim=num_classes,  # must match label count\n",
    "        depth=8,\n",
    "        flatten_output=False,\n",
    "        choice_function=entmax15,\n",
    "        bin_function=entmoid15\n",
    "    ),\n",
    "    Lambda(lambda x: x.mean(dim=-1))  # [B, C, D]  [B, C]\n",
    ").to(device)\n",
    "\n",
    "#  5. Initialize with dummy input (optional but recommended)\n",
    "with torch.no_grad():\n",
    "    _ = model(torch.as_tensor(data.X_train[:100], dtype=torch.float32, device=device))\n",
    "\n",
    "#  6. Create Trainer\n",
    "experiment_name = 'mqtt_classification_' + time.strftime(\"%Y.%m.%d_%H-%M-%S\", time.gmtime())\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    loss_function=F.cross_entropy,\n",
    "    experiment_name=experiment_name,\n",
    "    warm_start=False,\n",
    "    Optimizer=QHAdam,\n",
    "    optimizer_params=optimizer_params,\n",
    "    verbose=True,\n",
    "    n_last_checkpoints=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checkpoint updated: checkpoint_best.pth now points to the best model.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "src = \"logs/mqtt_classification_2025.07.16_18-02-36/checkpoint_temp_11500.pth\"\n",
    "dst = \"logs/mqtt_classification_2025.07.16_18-02-36/checkpoint_best.pth\"\n",
    "\n",
    "shutil.copyfile(src, dst)\n",
    "print(\" Checkpoint updated: checkpoint_best.pth now points to the best model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_100.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bcccu\\Desktop\\Node-Git\\node\\notebooks\\..\\lib\\trainer.py:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoints = [torch.load(path) for path in paths]\n",
      "c:\\Users\\bcccu\\Desktop\\Node-Git\\node\\notebooks\\..\\lib\\trainer.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_100.pth\n",
      " Loss: 5.75079\n",
      " Val Error Rate: 0.92562\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_200.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_200.pth\n",
      " Loss: 5.55258\n",
      " Val Error Rate: 0.90812\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_300.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_300.pth\n",
      " Loss: 5.35216\n",
      " Val Error Rate: 0.88426\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_400.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_400.pth\n",
      " Loss: 5.15645\n",
      " Val Error Rate: 0.85730\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_500.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_500.pth\n",
      " Loss: 4.94906\n",
      " Val Error Rate: 0.84121\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_600.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_600.pth\n",
      " Loss: 4.75438\n",
      " Val Error Rate: 0.82131\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_700.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_700.pth\n",
      " Loss: 4.57662\n",
      " Val Error Rate: 0.81440\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_800.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_800.pth\n",
      " Loss: 4.38945\n",
      " Val Error Rate: 0.81157\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_900.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_900.pth\n",
      " Loss: 4.19402\n",
      " Val Error Rate: 0.81101\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1000.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1000.pth\n",
      " Loss: 4.01890\n",
      " Val Error Rate: 0.80042\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1100.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1100.pth\n",
      " Loss: 3.82924\n",
      " Val Error Rate: 0.70529\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1200.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1200.pth\n",
      " Loss: 3.65567\n",
      " Val Error Rate: 0.68243\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1300.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1300.pth\n",
      " Loss: 3.51949\n",
      " Val Error Rate: 0.67481\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1400.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1400.pth\n",
      " Loss: 3.35391\n",
      " Val Error Rate: 0.64164\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1500.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1500.pth\n",
      " Loss: 3.21741\n",
      " Val Error Rate: 0.64206\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1600.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1600.pth\n",
      " Loss: 3.07762\n",
      " Val Error Rate: 0.64869\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1700.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1700.pth\n",
      " Loss: 2.94425\n",
      " Val Error Rate: 0.64813\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1800.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1800.pth\n",
      " Loss: 2.84266\n",
      " Val Error Rate: 0.64404\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1900.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_1900.pth\n",
      " Loss: 2.70560\n",
      " Val Error Rate: 0.63091\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2000.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2000.pth\n",
      " Loss: 2.63138\n",
      " Val Error Rate: 0.62216\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2100.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2100.pth\n",
      " Loss: 2.54922\n",
      " Val Error Rate: 0.62174\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2200.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2200.pth\n",
      " Loss: 2.43855\n",
      " Val Error Rate: 0.63275\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2300.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2300.pth\n",
      " Loss: 2.35681\n",
      " Val Error Rate: 0.64051\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2400.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2400.pth\n",
      " Loss: 2.25823\n",
      " Val Error Rate: 0.62879\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2500.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2500.pth\n",
      " Loss: 2.17270\n",
      " Val Error Rate: 0.57191\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2600.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2600.pth\n",
      " Loss: 2.12015\n",
      " Val Error Rate: 0.52040\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2700.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2700.pth\n",
      " Loss: 2.03187\n",
      " Val Error Rate: 0.50656\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2800.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2800.pth\n",
      " Loss: 1.97774\n",
      " Val Error Rate: 0.50275\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2900.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_2900.pth\n",
      " Loss: 1.87829\n",
      " Val Error Rate: 0.50049\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3000.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3000.pth\n",
      " Loss: 1.84462\n",
      " Val Error Rate: 0.49245\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3100.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3100.pth\n",
      " Loss: 1.77261\n",
      " Val Error Rate: 0.48610\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3200.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3200.pth\n",
      " Loss: 1.75839\n",
      " Val Error Rate: 0.48525\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3300.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3300.pth\n",
      " Loss: 1.70751\n",
      " Val Error Rate: 0.48483\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3400.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3400.pth\n",
      " Loss: 1.59342\n",
      " Val Error Rate: 0.48426\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3500.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3500.pth\n",
      " Loss: 1.56216\n",
      " Val Error Rate: 0.48398\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3600.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3600.pth\n",
      " Loss: 1.58194\n",
      " Val Error Rate: 0.47819\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3700.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3700.pth\n",
      " Loss: 1.50378\n",
      " Val Error Rate: 0.46972\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3800.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3800.pth\n",
      " Loss: 1.48268\n",
      " Val Error Rate: 0.46549\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3900.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_3900.pth\n",
      " Loss: 1.47268\n",
      " Val Error Rate: 0.46267\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4000.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4000.pth\n",
      " Loss: 1.42337\n",
      " Val Error Rate: 0.45716\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4100.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4100.pth\n",
      " Loss: 1.41530\n",
      " Val Error Rate: 0.44714\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4200.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4200.pth\n",
      " Loss: 1.36380\n",
      " Val Error Rate: 0.43881\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4300.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4300.pth\n",
      " Loss: 1.31116\n",
      " Val Error Rate: 0.43416\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4400.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4400.pth\n",
      " Loss: 1.31654\n",
      " Val Error Rate: 0.43246\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4500.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4500.pth\n",
      " Loss: 1.22094\n",
      " Val Error Rate: 0.42823\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4600.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4600.pth\n",
      " Loss: 1.24795\n",
      " Val Error Rate: 0.41821\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4700.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4700.pth\n",
      " Loss: 1.21234\n",
      " Val Error Rate: 0.39252\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4800.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4800.pth\n",
      " Loss: 1.20609\n",
      " Val Error Rate: 0.36217\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4900.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_4900.pth\n",
      " Loss: 1.13465\n",
      " Val Error Rate: 0.35229\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5000.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5000.pth\n",
      " Loss: 1.10296\n",
      " Val Error Rate: 0.34933\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5100.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5100.pth\n",
      " Loss: 1.10022\n",
      " Val Error Rate: 0.34749\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5200.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5200.pth\n",
      " Loss: 1.11997\n",
      " Val Error Rate: 0.34566\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5300.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5300.pth\n",
      " Loss: 1.06273\n",
      " Val Error Rate: 0.33550\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5400.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5400.pth\n",
      " Loss: 1.01944\n",
      " Val Error Rate: 0.30797\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5500.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5500.pth\n",
      " Loss: 0.97233\n",
      " Val Error Rate: 0.29838\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5600.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5600.pth\n",
      " Loss: 0.90514\n",
      " Val Error Rate: 0.29951\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5700.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5700.pth\n",
      " Loss: 0.99423\n",
      " Val Error Rate: 0.30049\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5800.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5800.pth\n",
      " Loss: 0.90601\n",
      " Val Error Rate: 0.29993\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5900.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_5900.pth\n",
      " Loss: 0.88978\n",
      " Val Error Rate: 0.30021\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6000.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6000.pth\n",
      " Loss: 0.99070\n",
      " Val Error Rate: 0.30092\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6100.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6100.pth\n",
      " Loss: 0.95301\n",
      " Val Error Rate: 0.30021\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6200.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6200.pth\n",
      " Loss: 0.94338\n",
      " Val Error Rate: 0.30106\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6300.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6300.pth\n",
      " Loss: 0.86874\n",
      " Val Error Rate: 0.30078\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6400.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6400.pth\n",
      " Loss: 0.88101\n",
      " Val Error Rate: 0.29965\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6500.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6500.pth\n",
      " Loss: 0.84129\n",
      " Val Error Rate: 0.29781\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6600.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6600.pth\n",
      " Loss: 0.89678\n",
      " Val Error Rate: 0.29626\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6700.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6700.pth\n",
      " Loss: 0.89867\n",
      " Val Error Rate: 0.29584\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6800.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6800.pth\n",
      " Loss: 0.88904\n",
      " Val Error Rate: 0.29457\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6900.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_6900.pth\n",
      " Loss: 0.82908\n",
      " Val Error Rate: 0.29386\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7000.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7000.pth\n",
      " Loss: 0.81642\n",
      " Val Error Rate: 0.26803\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7100.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7100.pth\n",
      " Loss: 0.79056\n",
      " Val Error Rate: 0.26817\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7200.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7200.pth\n",
      " Loss: 0.80549\n",
      " Val Error Rate: 0.26761\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7300.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7300.pth\n",
      " Loss: 0.82347\n",
      " Val Error Rate: 0.26789\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7400.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7400.pth\n",
      " Loss: 0.78068\n",
      " Val Error Rate: 0.26775\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7500.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7500.pth\n",
      " Loss: 0.74923\n",
      " Val Error Rate: 0.26690\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7600.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7600.pth\n",
      " Loss: 0.77765\n",
      " Val Error Rate: 0.26690\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7700.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7700.pth\n",
      " Loss: 0.77500\n",
      " Val Error Rate: 0.26620\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7800.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7800.pth\n",
      " Loss: 0.81759\n",
      " Val Error Rate: 0.26634\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7900.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_7900.pth\n",
      " Loss: 0.81387\n",
      " Val Error Rate: 0.26450\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8000.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8000.pth\n",
      " Loss: 0.81724\n",
      " Val Error Rate: 0.26478\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8100.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8100.pth\n",
      " Loss: 0.74680\n",
      " Val Error Rate: 0.26436\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8200.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8200.pth\n",
      " Loss: 0.77350\n",
      " Val Error Rate: 0.26210\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8300.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8300.pth\n",
      " Loss: 0.76104\n",
      " Val Error Rate: 0.26069\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8400.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8400.pth\n",
      " Loss: 0.73704\n",
      " Val Error Rate: 0.25603\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8500.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8500.pth\n",
      " Loss: 0.72377\n",
      " Val Error Rate: 0.25462\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8600.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8600.pth\n",
      " Loss: 0.73851\n",
      " Val Error Rate: 0.25434\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8700.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8700.pth\n",
      " Loss: 0.72422\n",
      " Val Error Rate: 0.25406\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8800.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8800.pth\n",
      " Loss: 0.64845\n",
      " Val Error Rate: 0.25378\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8900.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_8900.pth\n",
      " Loss: 0.71391\n",
      " Val Error Rate: 0.25335\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9000.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9000.pth\n",
      " Loss: 0.72464\n",
      " Val Error Rate: 0.25307\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9100.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9100.pth\n",
      " Loss: 0.73166\n",
      " Val Error Rate: 0.25265\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9200.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9200.pth\n",
      " Loss: 0.70824\n",
      " Val Error Rate: 0.25194\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9300.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9300.pth\n",
      " Loss: 0.72302\n",
      " Val Error Rate: 0.25166\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9400.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9400.pth\n",
      " Loss: 0.72058\n",
      " Val Error Rate: 0.25095\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9500.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9500.pth\n",
      " Loss: 0.70275\n",
      " Val Error Rate: 0.25067\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9600.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9600.pth\n",
      " Loss: 0.71676\n",
      " Val Error Rate: 0.25025\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9700.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9700.pth\n",
      " Loss: 0.69099\n",
      " Val Error Rate: 0.24926\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9800.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9800.pth\n",
      " Loss: 0.68923\n",
      " Val Error Rate: 0.24869\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9900.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_9900.pth\n",
      " Loss: 0.71161\n",
      " Val Error Rate: 0.24884\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10000.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10000.pth\n",
      " Loss: 0.69339\n",
      " Val Error Rate: 0.24827\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10100.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10100.pth\n",
      " Loss: 0.72794\n",
      " Val Error Rate: 0.24813\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10200.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10200.pth\n",
      " Loss: 0.74550\n",
      " Val Error Rate: 0.24813\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10300.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10300.pth\n",
      " Loss: 0.71201\n",
      " Val Error Rate: 0.24799\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10400.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10400.pth\n",
      " Loss: 0.68041\n",
      " Val Error Rate: 0.24771\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10500.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10500.pth\n",
      " Loss: 0.70295\n",
      " Val Error Rate: 0.24728\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10600.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10600.pth\n",
      " Loss: 0.70397\n",
      " Val Error Rate: 0.24785\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10700.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10700.pth\n",
      " Loss: 0.71767\n",
      " Val Error Rate: 0.24785\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10800.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10800.pth\n",
      " Loss: 0.68822\n",
      " Val Error Rate: 0.24869\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10900.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_10900.pth\n",
      " Loss: 0.71608\n",
      " Val Error Rate: 0.24827\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_11000.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_11000.pth\n",
      " Loss: 0.68231\n",
      " Val Error Rate: 0.24869\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_11100.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_11100.pth\n",
      " Loss: 0.67767\n",
      " Val Error Rate: 0.24785\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_11200.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_11200.pth\n",
      " Loss: 0.70737\n",
      " Val Error Rate: 0.24728\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_11300.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_11300.pth\n",
      " Loss: 0.61107\n",
      " Val Error Rate: 0.24714\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_11400.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_11400.pth\n",
      " Loss: 0.69937\n",
      " Val Error Rate: 0.24728\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_11500.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_avg.pth\n",
      "Saved logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_best.pth\n",
      "Loaded logs/mqtt_classification_2025.07.16_18-02-36\\checkpoint_temp_11500.pth\n",
      " Loss: 0.67334\n",
      " Val Error Rate: 0.24644\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "err_history = []\n",
    "best_val_err = float('inf')\n",
    "best_step = 0\n",
    "early_stopping_rounds = 5000\n",
    "report_frequency = 100\n",
    "\n",
    "for batch in lib.iterate_minibatches(data.X_train, data.y_train, batch_size=1024, \n",
    "                                      shuffle=True, epochs=float('inf')):\n",
    "\n",
    "    X_batch, y_batch = batch\n",
    "    X_batch = torch.tensor(X_batch, dtype=torch.float32).to(device)\n",
    "    y_batch = torch.tensor(y_batch, dtype=torch.long).to(device)\n",
    "\n",
    "    metrics = trainer.train_on_batch(X_batch, y_batch, device=device)\n",
    "    loss_history.append(metrics['loss'])\n",
    "\n",
    "    if trainer.step % report_frequency == 0:\n",
    "        trainer.save_checkpoint()\n",
    "        trainer.average_checkpoints(out_tag='avg')\n",
    "        trainer.load_checkpoint(tag='avg')\n",
    "\n",
    "        err = trainer.evaluate_classification_error(\n",
    "            data.X_valid, data.y_valid, device=device, batch_size=1024\n",
    "        )\n",
    "\n",
    "        if err < best_val_err:\n",
    "            best_val_err = err\n",
    "            best_step = trainer.stepca\n",
    "            trainer.save_checkpoint(tag='best')\n",
    "\n",
    "        err_history.append(err)\n",
    "        trainer.load_checkpoint()  # Reload last checkpoint\n",
    "        trainer.remove_old_temp_checkpoints()\n",
    "\n",
    "        print(\" Loss: %.5f\" % metrics['loss'])\n",
    "        print(\" Val Error Rate: %.5f\" % err)\n",
    "\n",
    "    if trainer.step > best_step + early_stopping_rounds:\n",
    "        print(f' Early Stopping after {early_stopping_rounds} steps without improvement.')\n",
    "        print(\" Best step: \", best_step)\n",
    "        print(\" Best Val Error Rate: %.5f\" % best_val_err)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Checkpoint copied to checkpoint_best.pth\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "src = \"C:/Users/bcccu/Desktop/Node-Git/node/notebooks/logs/mqtt_classification_2025.07.16_18-02-36/checkpoint_temp_11500.pth\"\n",
    "dst = \"C:/Users/bcccu/Desktop/Node-Git/node/notebooks/logs/mqtt_classification_2025.07.16_18-02-36/checkpoint_best.pth\"\n",
    "\n",
    "shutil.copyfile(src, dst)\n",
    "print(\" Checkpoint copied to checkpoint_best.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mexperiment_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/bcccu/Desktop/Node-Git/node/notebooks/logs/mqtt_classification_2025.07.16_18-02-36\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mload_checkpoint(tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.experiment_path = \"C:/Users/bcccu/Desktop/Node-Git/node/notebooks/logs/mqtt_classification_2025.07.16_18-02-36\"\n",
    "trainer.load_checkpoint(tag='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final Test Error Rate: 0.2399\n"
     ]
    }
   ],
   "source": [
    "test_err = trainer.evaluate_classification_error(\n",
    "    data.X_test, data.y_test, device=device, batch_size=1024\n",
    ")\n",
    "print(f\" Final Test Error Rate: {test_err:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape: (7086,)\n",
      "Predictions: [5 5 0 1 0 5 5 3 7 4]\n",
      "Classification report:                 precision    recall  f1-score   support\n",
      "\n",
      "   bf_dos/ddos       0.42      0.62      0.50       600\n",
      "    bruteforce       0.84      0.92      0.88       296\n",
      "delay_dos/ddos       0.71      0.14      0.24       600\n",
      "       malaria       0.94      0.96      0.95       600\n",
      "     malformed       0.93      0.95      0.94       585\n",
      "        normal       0.72      0.96      0.83      2400\n",
      "       slowite       1.00      0.99      1.00       205\n",
      "  sub_dos/ddos       0.92      0.82      0.86       600\n",
      "  syn_dos/ddos       0.71      0.35      0.47       600\n",
      " will_dos/ddos       0.97      0.52      0.68       600\n",
      "\n",
      "      accuracy                           0.76      7086\n",
      "     macro avg       0.82      0.72      0.73      7086\n",
      "  weighted avg       0.78      0.76      0.74      7086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def predict(model, X, device, batch_size=1024):\n",
    "\tpreds = []\n",
    "\twith torch.no_grad():\n",
    "\t\tfor i in range(0, len(X), batch_size):\n",
    "\t\t\txb = torch.tensor(X[i:i+batch_size], dtype=torch.float32).to(device)\n",
    "\t\t\tlogits = model(xb)\n",
    "\t\t\tpred = logits.argmax(dim=1).cpu().numpy()\n",
    "\t\t\tpreds.extend(pred)\n",
    "\treturn np.array(preds)\n",
    "\n",
    "preds = predict(trainer.model, data.X_test, device=device, batch_size=1024)\n",
    "print(\"Predictions shape:\", preds.shape)\n",
    "print(\"Predictions:\", preds[:10])  # Display first 10 predictions\n",
    "print(\"Classification report:\", classification_report(data.y_test, preds, target_names=class_names))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = trainer.predict(data.X_test, device=device, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bcccu\\Desktop\\Node-Git\\node\\notebooks\\..\\lib\\odst.py:113: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\"Data-aware initialization is performed on less than 1000 data points. This may cause instability.\"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Create proper train/validation/test splits\n",
    "X_temp, X_test_final, y_temp, y_test_final = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "X_train_final, X_valid, y_train_final, y_valid = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "# 2. Create dataset object compatible with lib.Trainer\n",
    "class CustomDataset:\n",
    "    def __init__(self, X_train, y_train, X_valid, y_valid, X_test, y_test):\n",
    "        self.X_train = X_train.values if hasattr(X_train, 'values') else X_train\n",
    "        self.y_train = y_train if isinstance(y_train, np.ndarray) else y_train.values\n",
    "        self.X_valid = X_valid.values if hasattr(X_valid, 'values') else X_valid\n",
    "        self.y_valid = y_valid if isinstance(y_valid, np.ndarray) else y_valid.values\n",
    "        self.X_test = X_test.values if hasattr(X_test, 'values') else X_test\n",
    "        self.y_test = y_test if isinstance(y_test, np.ndarray) else y_test.values\n",
    "\n",
    "data = CustomDataset(X_train_final, y_train_final, X_valid, y_valid, X_test_final, y_test_final)\n",
    "\n",
    "# 3. Create model\n",
    "input_dim = data.X_train.shape[1]\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "model = nn.Sequential(\n",
    "    lib.DenseBlock(\n",
    "        input_dim=input_dim,\n",
    "        layer_dim=64,              # Width of decision layers (can be tuned)\n",
    "        num_layers=2,              # Depth of stacked blocks\n",
    "        tree_dim=num_classes,      # Output classes = 10\n",
    "        depth=6,                   # Tree depth\n",
    "        flatten_output=False,      # Important: don't flatten\n",
    "        choice_function=lib.entmax15,\n",
    "        bin_function=lib.entmoid15\n",
    "    ),\n",
    "    lib.Lambda(lambda x: x.mean(dim=-1))  # [B, C, D]  [B, C] for F.cross_entropy\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "with torch.no_grad():\n",
    "    res = model(torch.as_tensor(data.X_train[:100], device=device))\n",
    "\n",
    "# 4. Create trainer with Windows-safe experiment name\n",
    "experiment_name = 'mqtt_classification'\n",
    "timestamp = time.strftime(\"%Y.%m.%d_%H-%M-%S\", time.gmtime())\n",
    "experiment_name = f\"{experiment_name}_{timestamp}\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    loss_function=F.cross_entropy,  # For classification\n",
    "    experiment_name=experiment_name,\n",
    "    warm_start=False,\n",
    "    Optimizer=QHAdam,\n",
    "    optimizer_params=optimizer_params,\n",
    "    verbose=True,\n",
    "    n_last_checkpoints=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "loss_history, err_history = [], []\n",
    "best_val_err = 1.0\n",
    "best_step = 0\n",
    "early_stopping_rounds = 10_000\n",
    "report_frequency = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final Logits Shape: torch.Size([17004, 128])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(torch.tensor(data.X_train, dtype=torch.float32, device=device))\n",
    "    print(\" Final Logits Shape:\", out.shape)  #  Should now be: [64, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1.38405\n",
      "Val Error Rate: 0.47459\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m X_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_batch, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_batch, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 13\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m loss_history\u001b[38;5;241m.\u001b[39mappend(metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m%\u001b[39m report_frequency \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\Desktop\\Node-Git\\node\\notebooks\\..\\lib\\trainer.py:123\u001b[0m, in \u001b[0;36mTrainer.train_on_batch\u001b[1;34m(self, device, *batch)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 123\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m)\u001b[49m, y_batch)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m    124\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\Desktop\\Node-Git\\node\\notebooks\\..\\lib\\arch.py:31\u001b[0m, in \u001b[0;36mDenseBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dropout:\n\u001b[0;32m     30\u001b[0m         layer_inp \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(layer_inp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_dropout)\n\u001b[1;32m---> 31\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_inp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, h], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     34\u001b[0m outputs \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, initial_features:]\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\Desktop\\Node-Git\\node\\notebooks\\..\\lib\\nn_utils.py:221\u001b[0m, in \u001b[0;36mModuleWithInit.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_initialized_tensor\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_initialized_bool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\Desktop\\Node-Git\\node\\notebooks\\..\\lib\\odst.py:84\u001b[0m, in \u001b[0;36mODST.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# new input shape: [batch_size, in_features]\u001b[39;00m\n\u001b[0;32m     83\u001b[0m feature_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_selection_logits\n\u001b[1;32m---> 84\u001b[0m feature_selectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# ^--[in_features, num_trees, depth]\u001b[39;00m\n\u001b[0;32m     87\u001b[0m feature_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbi,ind->bnd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28minput\u001b[39m, feature_selectors)\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\Desktop\\Node-Git\\node\\notebooks\\..\\lib\\nn_utils.py:186\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(input, dim)\u001b[0m\n\u001b[0;32m    182\u001b[0m         grad_input \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m*\u001b[39m gppr0\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m grad_input\n\u001b[1;32m--> 186\u001b[0m entmax15 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28minput\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m: \u001b[43mEntmax15Function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m entmoid15 \u001b[38;5;241m=\u001b[39m Entmoid15\u001b[38;5;241m.\u001b[39mapply\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLambda\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\Desktop\\Node-Git\\node\\notebooks\\..\\lib\\nn_utils.py:118\u001b[0m, in \u001b[0;36mEntmax15Function.forward\u001b[1;34m(ctx, input, dim)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m-\u001b[39m max_val  \u001b[38;5;66;03m# same numerical stability trick as for softmax\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# divide by 2 to solve actual Entmax\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m tau_star, _ \u001b[38;5;241m=\u001b[39m \u001b[43mEntmax15Function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_threshold_and_support\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28minput\u001b[39m \u001b[38;5;241m-\u001b[39m tau_star, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    120\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(output)\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\Desktop\\Node-Git\\node\\notebooks\\..\\lib\\nn_utils.py:135\u001b[0m, in \u001b[0;36mEntmax15Function._threshold_and_support\u001b[1;34m(input, dim)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_threshold_and_support\u001b[39m(\u001b[38;5;28minput\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 135\u001b[0m     Xsrt, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescending\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     rho \u001b[38;5;241m=\u001b[39m _make_ix_like(\u001b[38;5;28minput\u001b[39m, dim)\n\u001b[0;32m    138\u001b[0m     mean \u001b[38;5;241m=\u001b[39m Xsrt\u001b[38;5;241m.\u001b[39mcumsum(dim) \u001b[38;5;241m/\u001b[39m rho\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch in lib.iterate_minibatches(data.X_train, data.y_train, batch_size=1024, \n",
    "                                                shuffle=True, epochs=float('inf')):\n",
    "    X_batch, y_batch = batch\n",
    "    # Ensure y_batch is class indices, not one-hot\n",
    "    if hasattr(y_batch, 'shape') and y_batch.ndim > 1:\n",
    "        y_batch = np.argmax(y_batch, axis=1)\n",
    "    # If your model output has extra dimensions, squeeze it inside train_on_batch or here\n",
    "    # If you control train_on_batch, ensure it returns loss computed as:\n",
    "    # loss = F.cross_entropy(logits.squeeze(), y_batch)\n",
    "    X_batch = torch.tensor(X_batch, dtype=torch.float32).to(device)\n",
    "    y_batch = torch.tensor(y_batch, dtype=torch.long).to(device)\n",
    "\n",
    "    metrics = trainer.train_on_batch(X_batch, y_batch, device=device)\n",
    "    \n",
    "    loss_history.append(metrics['loss'])\n",
    "\n",
    "    if trainer.step % report_frequency == 0:\n",
    "        trainer.save_checkpoint()\n",
    "        trainer.average_checkpoints(out_tag='avg')\n",
    "        trainer.load_checkpoint(tag='avg')\n",
    "        err = trainer.evaluate_classification_error(\n",
    "            data.X_valid, data.y_valid, device=device, batch_size=1024)\n",
    "        \n",
    "        if err < best_val_err:\n",
    "            best_val_err = err\n",
    "            best_step = trainer.step\n",
    "            trainer.save_checkpoint(tag='best')\n",
    "        \n",
    "        err_history.append(err)\n",
    "        trainer.load_checkpoint()  # last\n",
    "        trainer.remove_old_temp_checkpoints()\n",
    "            \n",
    "        clear_output(True)\n",
    "        # plt.figure(figsize=[12, 6])\n",
    "        # plt.subplot(1, 2, 1)\n",
    "        # # Convert tensors in loss_history to numpy for plotting\n",
    "        # plt.plot([l.detach().cpu().numpy() if hasattr(l, 'detach') else l for l in loss_history])\n",
    "        # plt.grid()\n",
    "        # plt.subplot(1,2,2)\n",
    "        # plt.plot([float(e) for e in err_history])\n",
    "        # plt.grid()\n",
    "        # plt.show()\n",
    "        print(\"Loss %.5f\" % (metrics['loss']))\n",
    "        print(\"Val Error Rate: %0.5f\" % (err))\n",
    "        \n",
    "    if trainer.step > best_step + early_stopping_rounds:\n",
    "        print('BREAK. There is no improvment for {} steps'.format(early_stopping_rounds))\n",
    "        print(\"Best step: \", best_step)\n",
    "        print(\"Best Val Error Rate: %0.5f\" % (best_val_err))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'logs/mqtt_classification_2025.07.16_15-26-34\\\\checkpoint_best.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Set model to eval mode\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or use 'avg' if you averaged checkpoints\u001b[39;00m\n\u001b[0;32m      7\u001b[0m trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Inference function\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\Desktop\\Node-Git\\node\\notebooks\\..\\lib\\trainer.py:73\u001b[0m, in \u001b[0;36mTrainer.load_checkpoint\u001b[1;34m(self, tag, path, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(tag))\n\u001b[1;32m---> 73\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\bcccu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'logs/mqtt_classification_2025.07.16_15-26-34\\\\checkpoint_best.pth'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Set model to eval mode\n",
    "trainer.load_checkpoint(tag='best')  # or use 'avg' if you averaged checkpoints\n",
    "trainer.model.eval()\n",
    "\n",
    "# Inference function\n",
    "def predict(model, X, device, batch_size=1024):\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(X), batch_size):\n",
    "            xb = torch.tensor(X[i:i+batch_size], dtype=torch.float32).to(device)\n",
    "            logits = model(xb)\n",
    "            pred = logits.argmax(dim=1).cpu().numpy()\n",
    "            preds.extend(pred)\n",
    "    return np.array(preds)\n",
    "\n",
    "# Run prediction on test set\n",
    "y_pred = predict(trainer.model, data.X_test, device)\n",
    "\n",
    "# If your labels were encoded using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(data.y_train)  # Fit on training labels for correct mapping\n",
    "\n",
    "# Classification Report\n",
    "print(\" Classification Report:\")\n",
    "print(classification_report(data.y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\" Confusion Matrix:\")\n",
    "print(confusion_matrix(data.y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mload_checkpoint(tag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m error_rate \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate_classification_error(data\u001b[38;5;241m.\u001b[39mX_test, data\u001b[38;5;241m.\u001b[39my_test, device\u001b[38;5;241m=\u001b[39mdevice, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest step: \u001b[39m\u001b[38;5;124m'\u001b[39m, trainer\u001b[38;5;241m.\u001b[39mstep)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.load_checkpoint(tag='best')\n",
    "error_rate = trainer.evaluate_classification_error(data.X_test, data.y_test, device=device, batch_size=1024)\n",
    "print('Best step: ', trainer.step)\n",
    "print(\"Test Error rate: %0.5f\" % (error_rate))\n",
    "trainer.load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
